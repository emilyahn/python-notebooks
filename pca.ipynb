{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction with PCA\n",
    "\n",
    "Make a copy of [this Google Doc to note your answers](https://docs.google.com/a/wellesley.edu/document/d/1yShTnBSjlYWXESAD8a_s8JkUYKCjPlJZpjcGmHQT1eA/edit?usp=sharing) to the exercises, and share it with me.\n",
    "\n",
    "This notebook requires `numpy` and `sklearn`. If you don't have one or the other,\n",
    "join a team that does.\n",
    "\n",
    "## 0. Demonstration with Toy Data\n",
    "\n",
    "Let's start off with a simple 2-d example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "toydata = np.array([[ 2.59580335,  1.58213829], [-2.78661934, -1.64798522],\n",
    "       [ 1.63139824,  0.31923225], [ 3.30217587,  1.05792994],\n",
    "       [ 3.45343699,  2.63857074], [ 4.51845728,  1.70482163],\n",
    "       [ 1.62812508,  1.19761457], [ 4.56938036,  2.62619335],\n",
    "       [ 2.49414924,  0.69266559], [ 0.76665816,  0.83840976],\n",
    "       [ 2.99633637,  2.57876939], [ 1.23200454,  0.43656981],\n",
    "       [-1.5765329 ,  0.24567484], [ 0.12613358, -0.30435084],\n",
    "       [ 1.95787363,  0.9496059 ], [ 1.61221959,  2.25505992],\n",
    "       [ 3.01332383,  1.38350552], [ 5.10364862,  2.48569172],\n",
    "       [ 3.60794238,  1.79807615], [ 2.10190226,  1.1684013 ],\n",
    "       [ 2.02245627,  0.65881093], [ 3.43442621,  2.12150639],  \n",
    "        [ 1.59708639,  0.91357768],[ 2.82063906,  0.56994637],\n",
    "       [ 1.97769457,  0.92055868], [ 1.53287808,  0.83695528],\n",
    "       [-0.96349005,  0.00946347], [ 2.17383937,  0.69441521],\n",
    "       [ 1.60326191,  1.82933177], [ 1.62176519,  1.28228541]])\n",
    "\n",
    "# plot the original data\n",
    "plt.scatter(toydata[:, 0], toydata[:, 1])\n",
    "plt.show()\n",
    "\n",
    "# project the data onto 2 dimensions using sklearn's PCA \n",
    "toydimreduce2 = PCA(n_components=2)\n",
    "reducted_toydata = toydimreduce2.fit_transform(toydata-toydata.mean(axis=0))  \n",
    "# plot this data\n",
    "plt.scatter(reducted_toydata[:, 0], reducted_toydata[:, 1])\n",
    "plt.show()\n",
    "\n",
    "# display the eigenvectors\n",
    "print 'Principal Components (aka eigenvectors)'\n",
    "for c in toydimreduce2.components_:\n",
    "    print c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 0:** Convince yourself, by looking at the plot of the original data, that these eigenvectors are correct.\n",
    "\n",
    "## 1. Visualization of Dimension-Reduced Digits\n",
    "\n",
    "We project MNIST digits onto two dimensions using PCA and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "\n",
    "def load(url):\n",
    "    \"\"\"read a CSV from the web, return data and labels\"\"\"\n",
    "    response = urllib2.urlopen(url)\n",
    "    Xy = np.loadtxt(response, delimiter=',')\n",
    "    y = Xy[:, -1]\n",
    "    X = Xy[:, :-1]\n",
    "    return X, y\n",
    "\n",
    "trainX, trainy = load('http://cs.wellesley.edu/~sravana/ml/ps1/data/mnist1100/training.txt')\n",
    "print 'Loaded training data', trainX.shape\n",
    "\n",
    "# center the data \n",
    "trainXmean = np.mean(trainX, axis=0)\n",
    "trainX -= trainXmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run PCA\n",
    "from sklearn.decomposition import PCA\n",
    "dimreduce2 = PCA(n_components=2)\n",
    "reducedTrainX2 = dimreduce2.fit_transform(trainX)  \n",
    "# produces n by 2 matrix, where n = num of data points\n",
    "print 'Projected data onto 2 dimensions'\n",
    "\n",
    "# plot every 50th digit, just to reduce clutter\n",
    "reducedTrainX2_sample = reducedTrainX2[0::50, :]\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.scatter(reducedTrainX2_sample[:, 0], reducedTrainX2_sample[:, 1])\n",
    "for i in range(0, reducedTrainX2.shape[0], 50):  \n",
    "    plt.annotate(str(int(trainy[i])), (reducedTrainX2[i, 0], reducedTrainX2[i, 1]), size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1:** Looking at the visualization, think about classifying digits represented in this reduced 2-d space, using k Nearest Neighbors.\n",
    "\n",
    "What are some digits that could be confused for one another? What are the digits that would be most easily classified?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Classification on the reduced space\n",
    "\n",
    "How does a kNN classifier perform on the reduced representation?\n",
    "\n",
    "First, let's get the results for the original space. \n",
    "We'll use a fixed `k=3` and `metric=euclidean` for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from numpy.linalg import norm\n",
    "import time\n",
    "\n",
    "def plot_confusion_matrix(cm):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix (adapted from sklearn's doc)\n",
    "    \"\"\"\n",
    "    classes = range(cm.shape[0])\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "knnmodel = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "testX, testy = load('http://cs.wellesley.edu/~sravana/ml/ps1/data/mnist1100/testing.txt')\n",
    "print 'Loaded test data', testX.shape\n",
    "\n",
    "# center the data using the training mean\n",
    "testX -= trainXmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# baseline: kNN with no dimensionality reduction\n",
    "start = time.time()  # to time the computation\n",
    "knnmodel.fit(trainX, trainy)\n",
    "predy = knnmodel.predict(testX)\n",
    "print 'Accuracy of kNN:', 1-norm(predy-testy, 0)/float(testy.size)\n",
    "print 'Confusion matrix:'\n",
    "plot_confusion_matrix(confusion_matrix(testy, predy))\n",
    "print 'Ran in', time.time()-start, 'seconds'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same thing now with the dimension-reduced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# project test data on new space\n",
    "reducedTestX2 = dimreduce2.transform(testX)\n",
    "\n",
    "# kNN with 2-d dimensionality reduction\n",
    "start = time.time()\n",
    "knnmodel.fit(reducedTrainX2, trainy)\n",
    "predy = knnmodel.predict(reducedTestX2)\n",
    "print 'Accuracy of kNN:', 1-norm(predy-testy, 0)/float(testy.size)\n",
    "print 'Confusion matrix:'\n",
    "plot_confusion_matrix(confusion_matrix(testy, predy))\n",
    "\n",
    "print 'Ran in', time.time()-start, 'seconds'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2:** How does this result compare to your guesses in Exercise about the digits that would be confused and/or correctly classified?\n",
    "\n",
    "Okay, so 2-d wasn't great, but we're likely throwing away too much information going from 784 dimensions to only 2.\n",
    "\n",
    "2-d *is* nice for visualizations, though.\n",
    "\n",
    "**Exercise 3:** Observe the speedup of kNN running time for reduced data compared to the original. What was the speedup that you expected from the theoretical complexity?\n",
    "\n",
    "**Exercise 4**: In the cell below, try other numbers of dimensions to reduce the data to, and run the kNN classifier. Remember that you must estimate the principal components on the training data, and project the training as well as test data onto these, just like the code above. \n",
    "\n",
    "Can you beat the baseline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# write your code for PCA+kNN with other dimension values here\n",
    "dimreducek = PCA(n_components=20)\n",
    "reducedTrainXk = dimreducek.fit_transform(trainX)  \n",
    "knnmodel.fit(reducedTrainXk, trainy)\n",
    "reducedTestXk = dimreducek.transform(testX)\n",
    "predy = knnmodel.predict(reducedTestXk)\n",
    "print 'Accuracy of kNN:', 1-norm(predy-testy, 0)/float(testy.size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Eigendigits and Eigenfaces\n",
    "\n",
    "The above computations projected the original data onto the principal component vectors. But what do these vectors (in the original space) look like? The sklearn `PCA` class has an attribute called `components_` which are the eigenvectors, and `explained_variance_` which are the corresponding eigenvalues. \n",
    "\n",
    "Since these eigenvectors are in the original 784-dim pixel space, we can just visualize them as images.\n",
    "\n",
    "Let's compute the top 8 principal components and visualize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# visualize each component\n",
    "def visualize_images(imgvecs):\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    \n",
    "    # display grid shape\n",
    "    numrows = int(np.sqrt(len(imgvecs)))\n",
    "    numcols = int(len(imgvecs)/numrows)+1\n",
    "    \n",
    "    imgsize = int(np.sqrt(imgvecs.shape[1]))\n",
    "    \n",
    "    for i in range(len(imgvecs)):\n",
    "        c = imgvecs[i]\n",
    "        ax = fig.add_subplot(numrows,numcols,i+1)    \n",
    "        ax.axis('off')\n",
    "        ax.set_title(str(i))\n",
    "        ax.imshow(c.reshape(imgsize, imgsize), \n",
    "                  interpolation='none', cmap = plt.get_cmap('gray'))\n",
    "    plt.show()\n",
    "    \n",
    "def feat_reduce(data, numdims):\n",
    "    dimreduce = PCA(n_components=numdims)\n",
    "    reduced = dimreduce.fit_transform(data)  \n",
    "    eigenvectors = dimreduce.components_\n",
    "    print 'Visualizing the eigenvectors'\n",
    "    visualize_images(eigenvectors)\n",
    "    return reduced, eigenvectors\n",
    "    \n",
    "reducedTrainX8, _ = feat_reduce(trainX, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faces\n",
    "\n",
    "A more interesting example is PCA on images of faces. The code below loads a dataset of human faces and computes the principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "faces = fetch_olivetti_faces().data\n",
    "num_faces, num_dims = faces.shape\n",
    "print 'Loaded', num_faces, 'faces of', num_dims, 'pixels each'\n",
    "imgsize = np.sqrt(num_dims)\n",
    "\n",
    "# show two of the faces, as an example\n",
    "# note that these will be centered so the mean on each pixel is 0\n",
    "print 'Visualizing a few faces'\n",
    "visualize_images(faces[0:3, :])\n",
    "\n",
    "faces_mean = faces.mean(axis=0)\n",
    "faces -= faces_mean  # center the data, as required for PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run PCA on this dataset just as we did for the digits..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reducedFaces, face_eigenvectors = feat_reduce(faces, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An interpretation of these eigenvectors is that every face in the original data is a **linear combination of the eigenvectors above**. We'll call these eigenvectors \"eigenfaces\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visualize_images(faces[0:3, :]+faces_mean)\n",
    "np.set_printoptions(precision=2)\n",
    "print 'First face:', reducedFaces[0]\n",
    "print 'Second face:', reducedFaces[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is, the first face is -6.43 times the 1st eigenface plus -0.7 times the 2nd eigenface plus -1.43 times the 3rd eigenface plus 1.28 times the 4th eigenface, etc.\n",
    "\n",
    "In other words, each eigenface is a fundamental building block. We can say that *every face* is built by adding or subtracting some amount of each eigenface!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5:** Why did we add `faces_mean` before visualizing the first three vectors in `faces`? Hint: image pixel values range from 0 to 255. What are the ranges of the values in the centered images?\n",
    "\n",
    "**Exercise 6:** With the premise that each eigenface is a building block, what facial features would you say the displayed eigenfaces are primarily representing?\n",
    "\n",
    "Now let's visualize how the faces look when re-constructed (with the reduced dimensional faces projected onto the transpose of the eigenvectors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Showing original and reconstructed faces'\n",
    "\n",
    "for i in range(0, reducedFaces.shape[0], 50):  \n",
    "    # show original image\n",
    "    fig = plt.figure(figsize=(2, 2))\n",
    "    ax = fig.add_subplot(1,2,1)  \n",
    "    ax.axis('off')\n",
    "    ax.imshow((faces[i]+faces_mean).reshape(64, 64), \n",
    "               cmap = plt.get_cmap('gray'), \n",
    "               interpolation='none')\n",
    "    # multiply by eigenvectors' transpose to invert projection\n",
    "    reconstructed = reducedFaces[i].dot(face_eigenvectors)\n",
    "    ax = fig.add_subplot(1,2,2)  \n",
    "    ax.axis('off')\n",
    "    ax.imshow((reconstructed+faces_mean).reshape(64, 64),\n",
    "               cmap = plt.get_cmap('gray'), \n",
    "               interpolation='none')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7:** What is the dimensionality of `reducedFaces[i]`, `face_eigenvectors`, and the resulting dot product of the two?\n",
    "\n",
    "**Exercise 8:** Change the number of principal components in the call `feat_reduce` and re-run the above few cells. What is the minimum number of components needed to get good reconstructions of the faces (where \"good\" is your subjective assessment)? At what point does adding more components stop being of much benefit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Implementing PCA \n",
    "\n",
    "We don't need `sklearn` to compute the principal components of data. However, we do need an off-the-shelf algorithm, `numpy.linalg.eigh` (https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.eigh.html) to compute eigenvectors, since we're not learning how to do that in this class.\n",
    "\n",
    "**Exercise 9:** Follow the steps to implement PCA. \n",
    "\n",
    "Paste your code into the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy.linalg import eigh\n",
    "\n",
    "def pca(X):\n",
    "    \"\"\"Compute all the principal components of the vectors in the rows of X,\n",
    "    and project X onto these dimensions.\n",
    "    Return a tuple where the first item is an array of the principal components,\n",
    "    and the second item is the projected data\"\"\"\n",
    "    # 0. center the data so all the features have mean 0\n",
    "    \n",
    "    # 1. Compute X^T . X\n",
    "    \n",
    "    # 2. Compute the eigenvectors and eigenvalues of the above product\n",
    "    # numpy.linalg.eigh returns a tuple where the first value is a list \n",
    "    # of eigenvectors and the second is are\n",
    "    \n",
    "    # 3. sort the eigenvector rows in decreasing order of eigenvalue\n",
    "    \n",
    "    # 4. project X onto the eigenvector columns\n",
    "    \n",
    "    # 5. return a tuple of the eigenvectors (in order) and the projected data\n",
    "    \n",
    "    \n",
    "# trying with the 2-d data from section 0:\n",
    "\n",
    "# plot the original data\n",
    "plt.scatter(toydata[:, 0], toydata[:, 1])\n",
    "plt.show()\n",
    "\n",
    "eigenvectors_toy, reduced_toydata = pca(toydata)\n",
    "plt.scatter(reducted_toydata[:, 0], reducted_toydata[:, 1])\n",
    "plt.show()\n",
    "\n",
    "# display the eigenvectors\n",
    "print 'Principal Components (aka eigenvectors)'\n",
    "for c in eigenvectors_toy:\n",
    "    print c\n",
    "    \n",
    "# check that your plot and eigenvectors are the same\n",
    "# as the results from section 0 at the beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
